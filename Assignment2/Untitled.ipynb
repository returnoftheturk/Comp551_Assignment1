{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCsv(fileName):\n",
    "    fullFileName = r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\Assignments\\Assignment2\\Datasets\\DS' + fileName\n",
    "    df = pd.read_csv(fullFileName, encoding='utf-8', header = None,\n",
    "                 comment='#', sep=',')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(neighbors):\n",
    "    classCounter = Counter()\n",
    "    for neighbor in neighbors:\n",
    "        classCounter[neighbor[1]]+=1\n",
    "        \n",
    "    return classCounter.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kMM(testRow, dfTrain):\n",
    "    vectorTrainClass = dfTrain.iloc[:,20].as_matrix()\n",
    "    matrixTrain = dfTrain.iloc[:,0:20].as_matrix()\n",
    "    vectorTest = testRow[0:20].as_matrix()\n",
    "#     print(vectorTest)\n",
    "    subtractedMatrix = np.subtract(matrixTrain, vectorTest)\n",
    "    squareMatrix = np.square(subtractedMatrix)\n",
    "    distances = np.sqrt(np.sum(squareMatrix, axis = 1))\n",
    "    zipped = list(zip(distances, vectorTrainClass))\n",
    "    \n",
    "    return sorted(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getNNClass(testRow, k, dfTrain):\n",
    "    listSorted = kMM(testRow, dfTrain)\n",
    "    classCounter = vote(listSorted[0:k])\n",
    "    \n",
    "    return classCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterateTestData(dfTest, dfTrain, k):\n",
    "    predictions = list()\n",
    "    \n",
    "    for i in range(0, len(dfTest)):\n",
    "        predictions.append(getNNClass(dfTest.iloc[i,:], k, dfTrain))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 1\n",
      "Precision 0.541864139021\n",
      "Recall 0.554119547658\n",
      "F-Measure 0.547923322684\n",
      "K 3\n",
      "Precision 0.529886914378\n",
      "Recall 0.529886914378\n",
      "F-Measure 0.529886914378\n",
      "K 5\n",
      "Precision 0.535773710483\n",
      "Recall 0.520193861066\n",
      "F-Measure 0.527868852459\n",
      "K 10\n",
      "Precision 0.530405405405\n",
      "Recall 0.507269789984\n",
      "F-Measure 0.51857968621\n",
      "K 20\n",
      "Precision 0.541254125413\n",
      "Recall 0.529886914378\n",
      "F-Measure 0.535510204082\n",
      "K 50\n",
      "Precision 0.533101045296\n",
      "Recall 0.494345718901\n",
      "F-Measure 0.512992455993\n",
      "K 19\n",
      "Precision 0.544991511036\n",
      "Recall 0.518578352181\n",
      "F-Measure 0.531456953642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.54499151103565369, 0.51857835218093695, 0.5314569536423841)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testScores(dataset, k):\n",
    "    if dataset == 1:\n",
    "        dfTest = readCsv('1_test.csv')\n",
    "        dfTrain = readCsv('1_train.csv')\n",
    "    else:\n",
    "        dfTest = readCsv('2_test.csv')\n",
    "        dfTrain = readCsv('2_train.csv')\n",
    "    \n",
    "    predictionArray = iterateTestData(dfTest, dfTrain, k)\n",
    "    \n",
    "    dfTest = dfTest[20].as_matrix()\n",
    "#     print(dfTest)\n",
    "    truePositive,trueNegative, falsePositive, falseNegative = np.zeros(4)\n",
    "    for i in range(0, len(dfTest)):\n",
    "        if predictionArray[i]==1:\n",
    "            if dfTest[i]==1:\n",
    "                truePositive+=1\n",
    "            elif dfTest[i]==0:\n",
    "                falsePositive+=1\n",
    "        elif predictionArray[i]==0:\n",
    "            if dfTest[i]==1:\n",
    "                falseNegative+=1\n",
    "            elif dfTest[i]==0:\n",
    "                trueNegative+=1\n",
    "\n",
    "    precision = truePositive/(truePositive+falsePositive)\n",
    "    recall = truePositive/(truePositive+falseNegative)\n",
    "    fMeasure = 2*precision*recall/(precision+recall)\n",
    "    print('K', k)\n",
    "    print('Precision', precision)\n",
    "    print('Recall', recall)\n",
    "    print('F-Measure', fMeasure)\n",
    "    \n",
    "    return (precision, recall, fMeasure)\n",
    "\n",
    "testScores(2, 1)\n",
    "testScores(2, 3)\n",
    "testScores(2, 5)\n",
    "testScores(2, 10)\n",
    "testScores(2, 20)\n",
    "testScores(2, 50)\n",
    "testScores(2, 19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
