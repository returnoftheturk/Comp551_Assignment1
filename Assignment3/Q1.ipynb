{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "from collections import Counter\n",
    "import string\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from numpy.random import random_integers\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import tree\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readTxt(fileName):\n",
    "    fullFileName = r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\Assignments\\Assignment3\\Datasets' + fileName\n",
    "    df = pd.read_csv(fullFileName, encoding='utf-8', header = None,\n",
    "                 sep='\\t')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readCsv(fileName):\n",
    "    fullFileName = r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\Assignments\\Assignment3' + fileName\n",
    "    df = pd.read_csv(fullFileName, encoding='utf-8', header = None,\n",
    "                 sep=',')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toCsvDf(fileName, df):\n",
    "    fullFileName = r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\Assignments\\Assignment3\\Datasets' + fileName\n",
    "    df.to_csv(fullFileName, header = False, sep='\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toCsvNp(fileName, npArray):\n",
    "    fullFileName = r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\Assignments\\Assignment3\\Datasets' + fileName\n",
    "    np.savetxt(fullFileName, npArray, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "print(string.punctuation.replace('\\'', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 46529), ('and', 30692), ('i', 25255), ('a', 25145), ('to', 21190), ('of', 14457), ('was', 13736), ('is', 12124), ('it', 11898)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'the': 0,\n",
       " 'and': 1,\n",
       " 'i': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'of': 5,\n",
       " 'was': 6,\n",
       " 'is': 7,\n",
       " 'it': 8,\n",
       " 'for': 9,\n",
       " 'in': 10,\n",
       " 'that': 11,\n",
       " 'my': 12,\n",
       " 'with': 13,\n",
       " 'but': 14,\n",
       " 'you': 15,\n",
       " 'this': 16,\n",
       " 'they': 17,\n",
       " 'on': 18,\n",
       " 'we': 19,\n",
       " 'have': 20,\n",
       " 'not': 21,\n",
       " 'had': 22,\n",
       " 'are': 23,\n",
       " 'good': 24,\n",
       " 'so': 25,\n",
       " 'place': 26,\n",
       " 'at': 27,\n",
       " 'food': 28,\n",
       " 'were': 29,\n",
       " 'as': 30,\n",
       " 'be': 31,\n",
       " 'there': 32,\n",
       " 'great': 33,\n",
       " 'like': 34,\n",
       " 'if': 35,\n",
       " 'all': 36,\n",
       " 'its': 37,\n",
       " 'me': 38,\n",
       " 'out': 39,\n",
       " 'just': 40,\n",
       " 'very': 41,\n",
       " 'here': 42,\n",
       " 'one': 43,\n",
       " 'or': 44,\n",
       " 'their': 45,\n",
       " 'get': 46,\n",
       " 'from': 47,\n",
       " 'up': 48,\n",
       " 'go': 49,\n",
       " 'when': 50,\n",
       " 'time': 51,\n",
       " 'our': 52,\n",
       " 'really': 53,\n",
       " 'about': 54,\n",
       " 'some': 55,\n",
       " 'service': 56,\n",
       " 'would': 57,\n",
       " 'what': 58,\n",
       " 'an': 59,\n",
       " 'your': 60,\n",
       " 'can': 61,\n",
       " 'back': 62,\n",
       " 'which': 63,\n",
       " 'been': 64,\n",
       " 'more': 65,\n",
       " 'dont': 66,\n",
       " 'only': 67,\n",
       " 'also': 68,\n",
       " 'no': 69,\n",
       " 'will': 70,\n",
       " 'by': 71,\n",
       " 'well': 72,\n",
       " 'too': 73,\n",
       " 'love': 74,\n",
       " 'im': 75,\n",
       " 'nice': 76,\n",
       " 'has': 77,\n",
       " 'little': 78,\n",
       " 'other': 79,\n",
       " 'because': 80,\n",
       " 'ive': 81,\n",
       " 'them': 82,\n",
       " 'always': 83,\n",
       " 'do': 84,\n",
       " 'than': 85,\n",
       " 'even': 86,\n",
       " 'us': 87,\n",
       " 'best': 88,\n",
       " 'after': 89,\n",
       " 'pretty': 90,\n",
       " 'got': 91,\n",
       " 'he': 92,\n",
       " 'she': 93,\n",
       " 'chicken': 94,\n",
       " 'much': 95,\n",
       " 'try': 96,\n",
       " 'restaurant': 97,\n",
       " 'menu': 98,\n",
       " 'ordered': 99,\n",
       " 'people': 100,\n",
       " 'first': 101,\n",
       " 'know': 102,\n",
       " 'order': 103,\n",
       " 'over': 104,\n",
       " 'think': 105,\n",
       " 'didnt': 106,\n",
       " 'friendly': 107,\n",
       " 'could': 108,\n",
       " 'bar': 109,\n",
       " 'am': 110,\n",
       " 'went': 111,\n",
       " 'make': 112,\n",
       " 'staff': 113,\n",
       " 'never': 114,\n",
       " 'did': 115,\n",
       " 'off': 116,\n",
       " 'then': 117,\n",
       " 'better': 118,\n",
       " 'night': 119,\n",
       " 'way': 120,\n",
       " 'who': 121,\n",
       " 'going': 122,\n",
       " 'how': 123,\n",
       " 'right': 124,\n",
       " '2': 125,\n",
       " 'cheese': 126,\n",
       " 'made': 127,\n",
       " 'delicious': 128,\n",
       " 'few': 129,\n",
       " 'two': 130,\n",
       " 'pizza': 131,\n",
       " 'say': 132,\n",
       " 'came': 133,\n",
       " 'now': 134,\n",
       " 'want': 135,\n",
       " 'salad': 136,\n",
       " 'come': 137,\n",
       " 'lunch': 138,\n",
       " '5': 139,\n",
       " 'again': 140,\n",
       " 'sauce': 141,\n",
       " 'any': 142,\n",
       " 'new': 143,\n",
       " 'take': 144,\n",
       " 'still': 145,\n",
       " 'fresh': 146,\n",
       " '3': 147,\n",
       " 'while': 148,\n",
       " 'before': 149,\n",
       " 'see': 150,\n",
       " 'experience': 151,\n",
       " 'eat': 152,\n",
       " 'sure': 153,\n",
       " 'day': 154,\n",
       " 'down': 155,\n",
       " 'since': 156,\n",
       " 'cant': 157,\n",
       " 'definitely': 158,\n",
       " 'wait': 159,\n",
       " 'happy': 160,\n",
       " 'something': 161,\n",
       " 'find': 162,\n",
       " 'her': 163,\n",
       " 'around': 164,\n",
       " 'amazing': 165,\n",
       " 'most': 166,\n",
       " 'everything': 167,\n",
       " 'ever': 168,\n",
       " 'every': 169,\n",
       " 'times': 170,\n",
       " 'many': 171,\n",
       " 'though': 172,\n",
       " 'bit': 173,\n",
       " 'bad': 174,\n",
       " 'dinner': 175,\n",
       " 'give': 176,\n",
       " 'table': 177,\n",
       " 'said': 178,\n",
       " 'area': 179,\n",
       " 'meal': 180,\n",
       " 'next': 181,\n",
       " 'location': 182,\n",
       " 'lot': 183,\n",
       " 'into': 184,\n",
       " 'thing': 185,\n",
       " 'being': 186,\n",
       " 'phoenix': 187,\n",
       " 'side': 188,\n",
       " 'both': 189,\n",
       " 'where': 190,\n",
       " 'hour': 191,\n",
       " 'small': 192,\n",
       " 'last': 193,\n",
       " 'another': 194,\n",
       " '4': 195,\n",
       " 'prices': 196,\n",
       " 'favorite': 197,\n",
       " 'youre': 198,\n",
       " 'home': 199,\n",
       " 'big': 200,\n",
       " 'hot': 201,\n",
       " 'sandwich': 202,\n",
       " 'wasnt': 203,\n",
       " 'drink': 204,\n",
       " 'store': 205,\n",
       " 'beer': 206,\n",
       " 'tasty': 207,\n",
       " 'stars': 208,\n",
       " 'things': 209,\n",
       " 'drinks': 210,\n",
       " 'thats': 211,\n",
       " 'sweet': 212,\n",
       " '1': 213,\n",
       " 'his': 214,\n",
       " 'burger': 215,\n",
       " 'awesome': 216,\n",
       " 'feel': 217,\n",
       " 'minutes': 218,\n",
       " 'long': 219,\n",
       " 'wine': 220,\n",
       " 'looking': 221,\n",
       " 'fries': 222,\n",
       " 'worth': 223,\n",
       " 'enough': 224,\n",
       " 'atmosphere': 225,\n",
       " 'work': 226,\n",
       " 'bread': 227,\n",
       " 'should': 228,\n",
       " 'friends': 229,\n",
       " 'took': 230,\n",
       " 'different': 231,\n",
       " 'need': 232,\n",
       " 'room': 233,\n",
       " 'price': 234,\n",
       " 'old': 235,\n",
       " 'taste': 236,\n",
       " 'tried': 237,\n",
       " 'excellent': 238,\n",
       " 'recommend': 239,\n",
       " 'years': 240,\n",
       " 'huge': 241,\n",
       " 'clean': 242,\n",
       " 'breakfast': 243,\n",
       " '10': 244,\n",
       " 'ok': 245,\n",
       " 'coffee': 246,\n",
       " 'actually': 247,\n",
       " 'meat': 248,\n",
       " 'selection': 249,\n",
       " 'id': 250,\n",
       " 'free': 251,\n",
       " 'these': 252,\n",
       " 'those': 253,\n",
       " 'asked': 254,\n",
       " 'once': 255,\n",
       " 'places': 256,\n",
       " 'visit': 257,\n",
       " 'super': 258,\n",
       " 'found': 259,\n",
       " 'special': 260,\n",
       " 'scottsdale': 261,\n",
       " 'nothing': 262,\n",
       " 'check': 263,\n",
       " 'probably': 264,\n",
       " 'quality': 265,\n",
       " 'flavor': 266,\n",
       " 'quite': 267,\n",
       " 'kind': 268,\n",
       " 'server': 269,\n",
       " 'friend': 270,\n",
       " 'anything': 271,\n",
       " 'each': 272,\n",
       " 'thought': 273,\n",
       " 'wanted': 274,\n",
       " 'same': 275,\n",
       " 'perfect': 276,\n",
       " 'rice': 277,\n",
       " 'full': 278,\n",
       " 'look': 279,\n",
       " 'house': 280,\n",
       " 'why': 281,\n",
       " 'maybe': 282,\n",
       " 'usually': 283,\n",
       " 'sushi': 284,\n",
       " 'top': 285,\n",
       " 'ill': 286,\n",
       " 'cream': 287,\n",
       " 'large': 288,\n",
       " 'dish': 289,\n",
       " 'cool': 290,\n",
       " 'town': 291,\n",
       " 'however': 292,\n",
       " 'review': 293,\n",
       " 'beef': 294,\n",
       " 'away': 295,\n",
       " 'outside': 296,\n",
       " 'fried': 297,\n",
       " 'fun': 298,\n",
       " 'items': 299,\n",
       " 'without': 300,\n",
       " 'oh': 301,\n",
       " 'used': 302,\n",
       " 'far': 303,\n",
       " 'told': 304,\n",
       " 'spot': 305,\n",
       " 'parking': 306,\n",
       " 'inside': 307,\n",
       " 'half': 308,\n",
       " 'loved': 309,\n",
       " 'left': 310,\n",
       " 'open': 311,\n",
       " 'having': 312,\n",
       " 'enjoy': 313,\n",
       " 'decided': 314,\n",
       " 'served': 315,\n",
       " 'getting': 316,\n",
       " 'ask': 317,\n",
       " 'high': 318,\n",
       " 'else': 319,\n",
       " 'least': 320,\n",
       " 'three': 321,\n",
       " 'pork': 322,\n",
       " 'family': 323,\n",
       " 'everyone': 324,\n",
       " 'spicy': 325,\n",
       " 'patio': 326,\n",
       " 'hard': 327,\n",
       " 'may': 328,\n",
       " 'soup': 329,\n",
       " 'decent': 330,\n",
       " 'through': 331,\n",
       " 'red': 332,\n",
       " 'dishes': 333,\n",
       " 'enjoyed': 334,\n",
       " 'busy': 335,\n",
       " 'put': 336,\n",
       " 'overall': 337,\n",
       " 'music': 338,\n",
       " 'plate': 339,\n",
       " 'water': 340,\n",
       " 'restaurants': 341,\n",
       " 'couple': 342,\n",
       " 'makes': 343,\n",
       " 'ice': 344,\n",
       " 'chips': 345,\n",
       " 'eating': 346,\n",
       " 'course': 347,\n",
       " 'fantastic': 348,\n",
       " 'close': 349,\n",
       " 'whole': 350,\n",
       " 'kids': 351,\n",
       " 'almost': 352,\n",
       " 'wonderful': 353,\n",
       " 'star': 354,\n",
       " 'mexican': 355,\n",
       " 'such': 356,\n",
       " 'isnt': 357,\n",
       " 'yes': 358,\n",
       " 'fast': 359,\n",
       " 'wont': 360,\n",
       " 'part': 361,\n",
       " 'live': 362,\n",
       " 'fan': 363,\n",
       " 'husband': 364,\n",
       " 'green': 365,\n",
       " 'does': 366,\n",
       " 'chocolate': 367,\n",
       " 'own': 368,\n",
       " 'during': 369,\n",
       " 'dining': 370,\n",
       " 'shop': 371,\n",
       " 'hours': 372,\n",
       " 'tacos': 373,\n",
       " 'tables': 374,\n",
       " 'let': 375,\n",
       " 'doesnt': 376,\n",
       " 'care': 377,\n",
       " 'week': 378,\n",
       " 'reviews': 379,\n",
       " 'several': 380,\n",
       " 'local': 381,\n",
       " 'tasted': 382,\n",
       " 'stuff': 383,\n",
       " 'fish': 384,\n",
       " 'liked': 385,\n",
       " 'guy': 386,\n",
       " 'either': 387,\n",
       " 'especially': 388,\n",
       " 'less': 389,\n",
       " 'waitress': 390,\n",
       " 'valley': 391,\n",
       " 'shrimp': 392,\n",
       " 'looked': 393,\n",
       " 'steak': 394,\n",
       " 'style': 395,\n",
       " '6': 396,\n",
       " 'customer': 397,\n",
       " 'done': 398,\n",
       " 'must': 399,\n",
       " 'him': 400,\n",
       " 'door': 401,\n",
       " 'business': 402,\n",
       " 'yet': 403,\n",
       " 'finally': 404,\n",
       " 'coming': 405,\n",
       " 'quick': 406,\n",
       " 'sit': 407,\n",
       " 'use': 408,\n",
       " 'someone': 409,\n",
       " '20': 410,\n",
       " 'drive': 411,\n",
       " 'end': 412,\n",
       " 'although': 413,\n",
       " 'might': 414,\n",
       " 'stop': 415,\n",
       " 'real': 416,\n",
       " 'name': 417,\n",
       " 'myself': 418,\n",
       " 'disappointed': 419,\n",
       " 'bring': 420,\n",
       " 'line': 421,\n",
       " 'salsa': 422,\n",
       " 'cheap': 423,\n",
       " 'started': 424,\n",
       " 'year': 425,\n",
       " 'tell': 426,\n",
       " 'trying': 427,\n",
       " 'cooked': 428,\n",
       " 'yummy': 429,\n",
       " 'street': 430,\n",
       " 'thai': 431,\n",
       " 'fact': 432,\n",
       " 'dessert': 433,\n",
       " 'front': 434,\n",
       " 'waiting': 435,\n",
       " 'often': 436,\n",
       " 'seems': 437,\n",
       " 'money': 438,\n",
       " 'keep': 439,\n",
       " 'decor': 440,\n",
       " 'gave': 441,\n",
       " 'comes': 442,\n",
       " 'call': 443,\n",
       " 'until': 444,\n",
       " 'walk': 445,\n",
       " 'bacon': 446,\n",
       " 'seemed': 447,\n",
       " 'pay': 448,\n",
       " 'tea': 449,\n",
       " 'felt': 450,\n",
       " 'deal': 451,\n",
       " 'theres': 452,\n",
       " 'couldnt': 453,\n",
       " 'yelp': 454,\n",
       " '30': 455,\n",
       " 'lots': 456,\n",
       " 'today': 457,\n",
       " 'theyre': 458,\n",
       " 'helpful': 459,\n",
       " 'extra': 460,\n",
       " 'walked': 461,\n",
       " 'kitchen': 462,\n",
       " 'called': 463,\n",
       " 'glass': 464,\n",
       " 'instead': 465,\n",
       " 'person': 466,\n",
       " 'wrong': 467,\n",
       " 'able': 468,\n",
       " 'waiter': 469,\n",
       " 'brought': 470,\n",
       " 'okay': 471,\n",
       " 'second': 472,\n",
       " 'sat': 473,\n",
       " 'white': 474,\n",
       " 'guess': 475,\n",
       " 'plus': 476,\n",
       " 'group': 477,\n",
       " 'offer': 478,\n",
       " 'bbq': 479,\n",
       " 'needed': 480,\n",
       " 'wife': 481,\n",
       " 'wish': 482,\n",
       " 'etc': 483,\n",
       " 'regular': 484,\n",
       " 'fine': 485,\n",
       " 'owner': 486,\n",
       " 'options': 487,\n",
       " 'absolutely': 488,\n",
       " 'beans': 489,\n",
       " 'light': 490,\n",
       " 'saw': 491,\n",
       " 'highly': 492,\n",
       " '7': 493,\n",
       " 'wouldnt': 494,\n",
       " 'reason': 495,\n",
       " 'return': 496,\n",
       " 'start': 497,\n",
       " 'dog': 498,\n",
       " 'seem': 499,\n",
       " 'serve': 500,\n",
       " 'buy': 501,\n",
       " 'expect': 502,\n",
       " 'point': 503,\n",
       " 'help': 504,\n",
       " 'mind': 505,\n",
       " 'morning': 506,\n",
       " 'ago': 507,\n",
       " 'stay': 508,\n",
       " 'seen': 509,\n",
       " '15': 510,\n",
       " 'gets': 511,\n",
       " 'potato': 512,\n",
       " 'job': 513,\n",
       " 'flavors': 514,\n",
       " 'arizona': 515,\n",
       " 'size': 516,\n",
       " 'saturday': 517,\n",
       " 'four': 518,\n",
       " 'choice': 519,\n",
       " '8': 520,\n",
       " 'seating': 521,\n",
       " 'hotel': 522,\n",
       " 'impressed': 523,\n",
       " 'bowl': 524,\n",
       " 'roll': 525,\n",
       " 'appetizer': 526,\n",
       " 'later': 527,\n",
       " 'ate': 528,\n",
       " 'warm': 529,\n",
       " 'type': 530,\n",
       " 'arrived': 531,\n",
       " 'pick': 532,\n",
       " 'pool': 533,\n",
       " 'looks': 534,\n",
       " 'easy': 535,\n",
       " 'grilled': 536,\n",
       " 'list': 537,\n",
       " 'youll': 538,\n",
       " 'mall': 539,\n",
       " 'making': 540,\n",
       " 'beautiful': 541,\n",
       " 'car': 542,\n",
       " 'priced': 543,\n",
       " 'tempe': 544,\n",
       " 'perfectly': 545,\n",
       " 'sandwiches': 546,\n",
       " 'party': 547,\n",
       " 'between': 548,\n",
       " 'rolls': 549,\n",
       " 'portions': 550,\n",
       " 'burrito': 551,\n",
       " 'dry': 552,\n",
       " 'add': 553,\n",
       " '50': 554,\n",
       " 'game': 555,\n",
       " 'chinese': 556,\n",
       " 'wings': 557,\n",
       " 'potatoes': 558,\n",
       " 'trip': 559,\n",
       " 'days': 560,\n",
       " 'late': 561,\n",
       " 'run': 562,\n",
       " 'havent': 563,\n",
       " 'cute': 564,\n",
       " 'early': 565,\n",
       " 'attentive': 566,\n",
       " 'past': 567,\n",
       " 'ingredients': 568,\n",
       " 'quickly': 569,\n",
       " 'guys': 570,\n",
       " 'choose': 571,\n",
       " 'ended': 572,\n",
       " 'anyone': 573,\n",
       " 'average': 574,\n",
       " 'customers': 575,\n",
       " 'variety': 576,\n",
       " 'cold': 577,\n",
       " 'leave': 578,\n",
       " 'packed': 579,\n",
       " 'burgers': 580,\n",
       " 'extremely': 581,\n",
       " 'remember': 582,\n",
       " 'seriously': 583,\n",
       " 'twice': 584,\n",
       " 'plenty': 585,\n",
       " 'reasonable': 586,\n",
       " 'hit': 587,\n",
       " 'counter': 588,\n",
       " 'seated': 589,\n",
       " 'sitting': 590,\n",
       " 'problem': 591,\n",
       " 'park': 592,\n",
       " 'manager': 593,\n",
       " 'friday': 594,\n",
       " 'french': 595,\n",
       " 'cake': 596,\n",
       " 'date': 597,\n",
       " 'amount': 598,\n",
       " 'cut': 599,\n",
       " 'soon': 600,\n",
       " 'butter': 601,\n",
       " 'bite': 602,\n",
       " 'egg': 603,\n",
       " 'across': 604,\n",
       " 'short': 605,\n",
       " 'under': 606,\n",
       " 'show': 607,\n",
       " 'believe': 608,\n",
       " 'sometimes': 609,\n",
       " 'shopping': 610,\n",
       " 'five': 611,\n",
       " 'near': 612,\n",
       " 'sunday': 613,\n",
       " 'watch': 614,\n",
       " 'crust': 615,\n",
       " 'along': 616,\n",
       " 'working': 617,\n",
       " 'unique': 618,\n",
       " 'heard': 619,\n",
       " 'waited': 620,\n",
       " 'bill': 621,\n",
       " 'az': 622,\n",
       " 'slow': 623,\n",
       " 'weekend': 624,\n",
       " 'comfortable': 625,\n",
       " 'eaten': 626,\n",
       " 'others': 627,\n",
       " 'employees': 628,\n",
       " 'rather': 629,\n",
       " 'downtown': 630,\n",
       " 'man': 631,\n",
       " 'set': 632,\n",
       " 'neighborhood': 633,\n",
       " 'tip': 634,\n",
       " 'mean': 635,\n",
       " 'garlic': 636,\n",
       " '9': 637,\n",
       " 'anyway': 638,\n",
       " 'main': 639,\n",
       " 'surprised': 640,\n",
       " 'eggs': 641,\n",
       " 'beers': 642,\n",
       " '00': 643,\n",
       " 'ones': 644,\n",
       " 'w': 645,\n",
       " 'tomato': 646,\n",
       " 'crowd': 647,\n",
       " 'already': 648,\n",
       " '12': 649,\n",
       " 'hand': 650,\n",
       " 'pasta': 651,\n",
       " 'onion': 652,\n",
       " 'corn': 653,\n",
       " 'wow': 654,\n",
       " 'please': 655,\n",
       " 'ready': 656,\n",
       " 'evening': 657,\n",
       " 'italian': 658,\n",
       " 'girl': 659,\n",
       " 'life': 660,\n",
       " 'loud': 661,\n",
       " 'mom': 662,\n",
       " 'walking': 663,\n",
       " 'behind': 664,\n",
       " 'glad': 665,\n",
       " 'school': 666,\n",
       " 'simple': 667,\n",
       " 'chef': 668,\n",
       " 'expensive': 669,\n",
       " 'head': 670,\n",
       " 'ambiance': 671,\n",
       " 'stopped': 672,\n",
       " 'knew': 673,\n",
       " 'totally': 674,\n",
       " 'given': 675,\n",
       " 'space': 676,\n",
       " 'servers': 677,\n",
       " 'market': 678,\n",
       " 'doing': 679,\n",
       " 'authentic': 680,\n",
       " 'taking': 681,\n",
       " 'crispy': 682,\n",
       " 'salads': 683,\n",
       " 'specials': 684,\n",
       " 'entire': 685,\n",
       " 'available': 686,\n",
       " 'offered': 687,\n",
       " 'read': 688,\n",
       " 'taco': 689,\n",
       " 'sausage': 690,\n",
       " 'thanks': 691,\n",
       " 'portion': 692,\n",
       " 'hands': 693,\n",
       " 'hope': 694,\n",
       " 'itself': 695,\n",
       " 'flavorful': 696,\n",
       " 'yourself': 697,\n",
       " 'feeling': 698,\n",
       " 'appetizers': 699,\n",
       " 'ordering': 700,\n",
       " 'expected': 701,\n",
       " 'gone': 702,\n",
       " 'black': 703,\n",
       " 'arent': 704,\n",
       " 'plates': 705,\n",
       " 'chain': 706,\n",
       " 'world': 707,\n",
       " 'card': 708,\n",
       " 'cost': 709,\n",
       " 'completely': 710,\n",
       " 'sort': 711,\n",
       " 'moved': 712,\n",
       " 'cup': 713,\n",
       " 'kept': 714,\n",
       " 'thank': 715,\n",
       " 'pho': 716,\n",
       " 'entrees': 717,\n",
       " 'toppings': 718,\n",
       " 'hair': 719,\n",
       " 'unfortunately': 720,\n",
       " 'choices': 721,\n",
       " 'yum': 722,\n",
       " 'opened': 723,\n",
       " 'rest': 724,\n",
       " 'joint': 725,\n",
       " 'spend': 726,\n",
       " 'change': 727,\n",
       " 'dark': 728,\n",
       " 'months': 729,\n",
       " 'miss': 730,\n",
       " 'located': 731,\n",
       " 'wall': 732,\n",
       " 'club': 733,\n",
       " 'recently': 734,\n",
       " 'idea': 735,\n",
       " 'foods': 736,\n",
       " 'birthday': 737,\n",
       " 'bucks': 738,\n",
       " 'typical': 739,\n",
       " 'mac': 740,\n",
       " 'cafe': 741,\n",
       " 'interesting': 742,\n",
       " 'werent': 743,\n",
       " 'onions': 744,\n",
       " 'tastes': 745,\n",
       " 'including': 746,\n",
       " 'center': 747,\n",
       " 'mouth': 748,\n",
       " 'asian': 749,\n",
       " 'curry': 750,\n",
       " 'grab': 751,\n",
       " 'pieces': 752,\n",
       " 'bland': 753,\n",
       " 'needs': 754,\n",
       " 'bottle': 755,\n",
       " 'grill': 756,\n",
       " 'together': 757,\n",
       " 'exactly': 758,\n",
       " 'kinda': 759,\n",
       " 'meals': 760,\n",
       " 'play': 761,\n",
       " 'non': 762,\n",
       " 'lettuce': 763,\n",
       " 'empty': 764,\n",
       " 'hungry': 765,\n",
       " 'blue': 766,\n",
       " 'office': 767,\n",
       " 'yeah': 768,\n",
       " 'toast': 769,\n",
       " 'low': 770,\n",
       " 'saying': 771,\n",
       " 'bartender': 772,\n",
       " 'crowded': 773,\n",
       " 'note': 774,\n",
       " 'charge': 775,\n",
       " 'summer': 776,\n",
       " 'spring': 777,\n",
       " 'excited': 778,\n",
       " 'unless': 779,\n",
       " 'stand': 780,\n",
       " 'truly': 781,\n",
       " 'outdoor': 782,\n",
       " 'recommended': 783,\n",
       " 'event': 784,\n",
       " 'noodles': 785,\n",
       " 'understand': 786,\n",
       " 'pricey': 787,\n",
       " 'afternoon': 788,\n",
       " 'veggies': 789,\n",
       " 'tiny': 790,\n",
       " 'pie': 791,\n",
       " 'mixed': 792,\n",
       " 'longer': 793,\n",
       " 'based': 794,\n",
       " 'talk': 795,\n",
       " 'salmon': 796,\n",
       " 'stores': 797,\n",
       " 'hate': 798,\n",
       " 'crab': 799,\n",
       " 'chance': 800,\n",
       " 'desert': 801,\n",
       " 'soft': 802,\n",
       " 'owners': 803,\n",
       " 'strip': 804,\n",
       " 'dressing': 805,\n",
       " 'sides': 806,\n",
       " 'tasting': 807,\n",
       " 'sorry': 808,\n",
       " 'tender': 809,\n",
       " 'oil': 810,\n",
       " 'company': 811,\n",
       " 'noticed': 812,\n",
       " 'frozen': 813,\n",
       " 'filled': 814,\n",
       " 'pleasant': 815,\n",
       " 'cannot': 816,\n",
       " 'anywhere': 817,\n",
       " 'giving': 818,\n",
       " 'movie': 819,\n",
       " 'greasy': 820,\n",
       " 'true': 821,\n",
       " 'homemade': 822,\n",
       " 'casual': 823,\n",
       " 'closed': 824,\n",
       " 'lets': 825,\n",
       " 'single': 826,\n",
       " 'dip': 827,\n",
       " 'number': 828,\n",
       " 'phone': 829,\n",
       " 'shared': 830,\n",
       " 'veggie': 831,\n",
       " 'forward': 832,\n",
       " 'goes': 833,\n",
       " 'spinach': 834,\n",
       " 'watching': 835,\n",
       " 'thin': 836,\n",
       " 'craving': 837,\n",
       " 'within': 838,\n",
       " 'whatever': 839,\n",
       " 'piece': 840,\n",
       " 'prepared': 841,\n",
       " 'ribs': 842,\n",
       " 'bought': 843,\n",
       " 'share': 844,\n",
       " 'case': 845,\n",
       " 'girls': 846,\n",
       " 'above': 847,\n",
       " 'dirty': 848,\n",
       " 'healthy': 849,\n",
       " 'upon': 850,\n",
       " 'entree': 851,\n",
       " 'playing': 852,\n",
       " 'vegetarian': 853,\n",
       " 'fabulous': 854,\n",
       " 'pita': 855,\n",
       " 'lovely': 856,\n",
       " 'value': 857,\n",
       " 'face': 858,\n",
       " 'sports': 859,\n",
       " 'finish': 860,\n",
       " 'slightly': 861,\n",
       " 'la': 862,\n",
       " 'orders': 863,\n",
       " 'dogs': 864,\n",
       " 'mix': 865,\n",
       " 'weeks': 866,\n",
       " '11': 867,\n",
       " 'horrible': 868,\n",
       " 'mine': 869,\n",
       " 'youve': 870,\n",
       " 'lady': 871,\n",
       " 'box': 872,\n",
       " 'city': 873,\n",
       " 'roasted': 874,\n",
       " 'bag': 875,\n",
       " 'stuffed': 876,\n",
       " 'total': 877,\n",
       " 'talking': 878,\n",
       " 'dr': 879,\n",
       " 'literally': 880,\n",
       " 'tuna': 881,\n",
       " '100': 882,\n",
       " 'floor': 883,\n",
       " 'takes': 884,\n",
       " 'fruit': 885,\n",
       " 'hang': 886,\n",
       " 'fair': 887,\n",
       " 'airport': 888,\n",
       " 'filling': 889,\n",
       " 'serving': 890,\n",
       " 'corner': 891,\n",
       " 'n': 892,\n",
       " 'perhaps': 893,\n",
       " 'book': 894,\n",
       " 'spent': 895,\n",
       " 'added': 896,\n",
       " 'pizzas': 897,\n",
       " 'brunch': 898,\n",
       " 'worst': 899,\n",
       " 'tomatoes': 900,\n",
       " 'month': 901,\n",
       " 'fairly': 902,\n",
       " 'middle': 903,\n",
       " 'terrible': 904,\n",
       " 'except': 905,\n",
       " 'tons': 906,\n",
       " 'thinking': 907,\n",
       " 'easily': 908,\n",
       " '25': 909,\n",
       " 'works': 910,\n",
       " 'simply': 911,\n",
       " 'weve': 912,\n",
       " 'sign': 913,\n",
       " 'vibe': 914,\n",
       " 'split': 915,\n",
       " 'sauces': 916,\n",
       " 'chili': 917,\n",
       " 'somewhere': 918,\n",
       " 'prefer': 919,\n",
       " 'buffet': 920,\n",
       " 'says': 921,\n",
       " 'crazy': 922,\n",
       " 'view': 923,\n",
       " 'received': 924,\n",
       " 'weird': 925,\n",
       " 'due': 926,\n",
       " 'item': 927,\n",
       " 'seats': 928,\n",
       " 'building': 929,\n",
       " 'heat': 930,\n",
       " 'cash': 931,\n",
       " 'forget': 932,\n",
       " 'word': 933,\n",
       " 'immediately': 934,\n",
       " 'finished': 935,\n",
       " 'pulled': 936,\n",
       " 'games': 937,\n",
       " 'orange': 938,\n",
       " 'hear': 939,\n",
       " 'boyfriend': 940,\n",
       " 'beat': 941,\n",
       " 'salty': 942,\n",
       " 'attention': 943,\n",
       " 'alone': 944,\n",
       " 'section': 945,\n",
       " 'baked': 946,\n",
       " 'art': 947,\n",
       " 'shot': 948,\n",
       " 'traditional': 949,\n",
       " 'die': 950,\n",
       " 'turkey': 951,\n",
       " 'hummus': 952,\n",
       " 'picked': 953,\n",
       " 'daughter': 954,\n",
       " 'taken': 955,\n",
       " 'stayed': 956,\n",
       " 'paying': 957,\n",
       " 'honestly': 958,\n",
       " 'seat': 959,\n",
       " 'medium': 960,\n",
       " 'mostly': 961,\n",
       " 'paid': 962,\n",
       " 'means': 963,\n",
       " 'treat': 964,\n",
       " 'minute': 965,\n",
       " 'soda': 966,\n",
       " 'slice': 967,\n",
       " 'lived': 968,\n",
       " 'matter': 969,\n",
       " 'personal': 970,\n",
       " 'damn': 971,\n",
       " 'sad': 972,\n",
       " 'combo': 973,\n",
       " 'crisp': 974,\n",
       " 'certainly': 975,\n",
       " 'east': 976,\n",
       " 'visiting': 977,\n",
       " 'nights': 978,\n",
       " 'north': 979,\n",
       " 'mention': 980,\n",
       " 'bars': 981,\n",
       " 'salt': 982,\n",
       " 'vegan': 983,\n",
       " '99': 984,\n",
       " 'iced': 985,\n",
       " 'guacamole': 986,\n",
       " 'nearly': 987,\n",
       " 'central': 988,\n",
       " 'seafood': 989,\n",
       " 'american': 990,\n",
       " 'mood': 991,\n",
       " 's': 992,\n",
       " 'greeted': 993,\n",
       " 'option': 994,\n",
       " 'opinion': 995,\n",
       " 'baby': 996,\n",
       " 'thick': 997,\n",
       " 'yogurt': 998,\n",
       " 'tortilla': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createDictionary(trainingSet):\n",
    "    allWords = list()\n",
    "    cnt = Counter()\n",
    "    \n",
    "    if trainingSet=='IMDB':\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "    elif trainingSet=='yelp':\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "    \n",
    "# Replacing !\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~ with ' ' * 31 (31 spaces, needs to be same length)\n",
    "# and replacing ' with ' ' (apostrophe with space)\n",
    "    translator = str.maketrans(string.punctuation.replace('\\'', ''), 31*' ', '\\'')\n",
    "    \n",
    "    for i in range(0, len(trainingDF)):\n",
    "        allWords.extend(trainingDF.iloc[i,0].translate(translator).lower().split(\" \"))\n",
    "    \n",
    "    for word in allWords:\n",
    "        cnt[word] +=1\n",
    "    print(cnt.most_common(10)[1:])\n",
    "    dictionaryWords = list(zip(*cnt.most_common(10001)[1:]))[0]\n",
    "    \n",
    "    dictionary = {}\n",
    "    for index, key in enumerate(dictionaryWords):\n",
    "        dictionary[key] = index\n",
    "#     print(dictionary)\n",
    "    newArray = np.asarray(cnt.most_common(10001)[1:])\n",
    "    withIndexVocabArray = np.insert(newArray, 1, range(0,10000),1)\n",
    "    \n",
    "    if trainingSet=='IMDB':\n",
    "        toCsvDf('\\IMDB-vocab.txt', pd.DataFrame(withIndexVocabArray))\n",
    "    elif trainingSet=='yelp':\n",
    "        toCsvDf('\\yelp-vocab.txt', pd.DataFrame(withIndexVocabArray))\n",
    "        \n",
    "    return dictionary\n",
    "createDictionary('yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertWordsToVector(trainingRow, dictionary, BOWType):\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    returnRow = trainingRow.translate(translator).lower().split(\" \")\n",
    "    vector = np.zeros(10000, dtype = np.int8)\n",
    "    \n",
    "    for word in returnRow:\n",
    "        if word in dictionary:\n",
    "            if BOWType == 'BagOfWords':\n",
    "                vector[dictionary[word]] = np.int8(1)\n",
    "            elif BOWType == 'Frequency':\n",
    "                vector[dictionary[word]] += 1\n",
    "    \n",
    "    if BOWType == 'Frequency':\n",
    "#         To accomodate for the fact that one of the rows has one word, d-gust-ing, and the lenght of the vector is zero.\n",
    "#         Hence, the vector returns [Nan Nan Nan ... Nan Nan].  Now it returns [0 0 0 ... 0 0 0]\n",
    "        vectorLength =  np.sum(vector)\n",
    "        if vectorLength>0:\n",
    "            vector = np.divide(vector, vectorLength)\n",
    "            \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05434783  0.02173913  0.00543478 ...,  0.          0.          0.        ]\n",
      " [ 0.03488372  0.03488372  0.0872093  ...,  0.          0.          0.        ]\n",
      " [ 0.05555556  0.03703704  0.04938272 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.03333333  0.075       0.04166667 ...,  0.          0.          0.        ]\n",
      " [ 0.08029197  0.03832117  0.05291971 ...,  0.          0.          0.        ]\n",
      " [ 0.02777778  0.05555556  0.         ...,  0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "def createBagOfWordsMatrix(df, dictionary, BOWType):\n",
    "    translator = str.maketrans('','', string.punctuation)\n",
    "    \n",
    "    if BOWType == 'BagOfWords':\n",
    "        distancesArray = np.zeros((len(df), len(dictionary)), dtype = np.int8)\n",
    "    elif BOWType == 'Frequency':\n",
    "        distancesArray = np.zeros((len(df), len(dictionary)))\n",
    "        \n",
    "    for i in range(0, len(df)):\n",
    "        vector = convertWordsToVector(df.iloc[i,0], dictionary, BOWType)\n",
    "        distancesArray[i] = vector\n",
    "#         print(np.sum(distancesArray[i]))\n",
    "    return distancesArray\n",
    "# trainingDF = \n",
    "# npArray = createBagOfWordsMatrix(readTxt('\\yelp-train.txt'), createDictionary('yelp'), 'Frequency')\n",
    "print(createBagOfWordsMatrix(readTxt('\\yelp-train.txt'), createDictionary('yelp'), 'Frequency'))\n",
    "# dfArray = pd.DataFrame(npArray)\n",
    "# dfArray.to_csv(r'C:\\Users\\Owner\\McGill\\4thYear\\COMP551\\Assignments\\Assignment3\\Datasets\\TESTING2.csv', header = False, sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i cant believe i havent yelped about the place yet several months maybe over a year ago my husband read a newspaper article about the clover coffee maker and the one place in town that had managed to one i was skeptical as is my nature it cant be that much better right youre just saying its amazing because you want to talk about the new hot coffee shop you discovered right well maybe but i love this place and i dont think it has a whole lot to do with the clover they roast their own beans and they roast them way differently than that other ginormous coffee chain  all a light or medium roast never bitter never oily never yucky the coffee they make there is obviously the best but i send my husband in every week now to buy a pound of beans so that i can the same coffee at home add an edgy though sometimes intimidating seating area great local art which we bought off the wall and smiley sold cant wait to try out the downtown location \n",
      "best nights to go to postinos are mondays and tuesdays  they offer 20 deals where you get 4 slices of bruschetta out of the 12 that they offer and one whole bottle of the house wine  each bruschetta slice is probably the size of maybe your hand with your fingers  if youre a petite girl     they then cut each slice into 4s  perfect for went on a monday night after 8pm and ordered 2 bottles of wine the 2 orders of the bruschetta which were 8 slices for those that cant count and a bowl of olives  the total came out to about a little over wo tip  awesome    plus they have complementary valet parking everything was just fantastic ive never had fig before and they made my experience there quite memorable  i definitely recommend you come in regardless if its for their 20 deals on or not  theyve got great food and i will be back \n"
     ]
    }
   ],
   "source": [
    "def createReviewsTxt(df, dictionary):\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    \n",
    "    \n",
    "    for i in range(0, 2):\n",
    "        reviewsString = ''\n",
    "        trainingRow = df.iloc[i,0].translate(translator).lower().split(\" \")\n",
    "        for word in trainingRow:\n",
    "            if word in dictionary:\n",
    "                reviewsString += word + ' '\n",
    "        print(reviewsString)\n",
    "            \n",
    "createReviewsTxt(readTxt('\\yelp-train.txt'), createDictionary('yelp'))        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def testScores(predicted, actual):\n",
    "    print('F1 Score:', f1_score(actual, predicted, average='macro'))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(actual, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp Random Classifier\n",
      "Training F1-Measure\n",
      "F1 Score: 0.184123905128\n",
      "Confusion Matrix:\n",
      " [[107 106  96 119  94]\n",
      " [124 129 115 137 136]\n",
      " [202 203 199 199 194]\n",
      " [503 478 484 497 506]\n",
      " [473 462 483 464 490]]\n",
      "Validation F1-Measure\n",
      "F1 Score: 0.176673463167\n",
      "Confusion Matrix:\n",
      " [[14 15 23 18 14]\n",
      " [24 16 20 12 24]\n",
      " [25 35 37 34 33]\n",
      " [62 68 82 74 70]\n",
      " [58 48 70 71 53]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.18894982874\n",
      "Confusion Matrix:\n",
      " [[ 27  29  25  33  29]\n",
      " [ 37  40  38  36  39]\n",
      " [ 63  54  60  65  58]\n",
      " [126 164 135 145 132]\n",
      " [122 127 133 136 147]]\n"
     ]
    }
   ],
   "source": [
    "def randomClassifier(dataset):\n",
    "    print(dataset, 'Random Classifier')\n",
    "    if dataset == 'yelp':\n",
    "        dictionary = createDictionary('yelp')\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "        validDF = readTxt('\\yelp-valid.txt')\n",
    "        testDF = readTxt('\\yelp-test.txt')\n",
    "    elif dataset == 'IMDB':\n",
    "        dictionary = createDictionary('IMDB')\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "        validDF = readTxt('\\IMDB-valid.txt')\n",
    "        testDF = readTxt('\\IMDB-test.txt')\n",
    "    \n",
    "    randomClassifier = DummyClassifier(strategy='uniform')\n",
    "    randomClassifier.fit(createBagOfWordsMatrix(trainingDF, dictionary), trainingDF[1])\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = randomClassifier.predict(createBagOfWordsMatrix(trainingDF, dictionary))\n",
    "    testScores(predictionsArray, trainingDF[1])\n",
    "    \n",
    "    print('Validation F1-Measure')\n",
    "    predictionsArray = randomClassifier.predict(createBagOfWordsMatrix(validDF, dictionary))\n",
    "    testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = randomClassifier.predict(createBagOfWordsMatrix(testDF, dictionary))\n",
    "    testScores(predictionsArray, testDF[1])\n",
    "    \n",
    "randomClassifier('yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp Majority Classifier\n",
      "Training F1-Measure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.104267004647\n",
      "Confusion Matrix:\n",
      " [[   0    0    0  522    0]\n",
      " [   0    0    0  641    0]\n",
      " [   0    0    0  997    0]\n",
      " [   0    0    0 2468    0]\n",
      " [   0    0    0 2372    0]]\n",
      "Validation F1-Measure\n",
      "F1 Score: 0.105014749263\n",
      "Confusion Matrix:\n",
      " [[  0   0   0  84   0]\n",
      " [  0   0   0  96   0]\n",
      " [  0   0   0 164   0]\n",
      " [  0   0   0 356   0]\n",
      " [  0   0   0 300   0]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.103923019985\n",
      "Confusion Matrix:\n",
      " [[  0   0   0 143   0]\n",
      " [  0   0   0 190   0]\n",
      " [  0   0   0 300   0]\n",
      " [  0   0   0 702   0]\n",
      " [  0   0   0 665   0]]\n"
     ]
    }
   ],
   "source": [
    "def majorityClassifier(dataset):\n",
    "    print(dataset, 'Majority Classifier')\n",
    "    if dataset == 'yelp':\n",
    "        dictionary = createDictionary('yelp')\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "        validDF = readTxt('\\yelp-valid.txt')\n",
    "        testDF = readTxt('\\yelp-test.txt')\n",
    "    elif dataset == 'IMDB':\n",
    "        dictionary = createDictionary('IMDB')\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "        validDF = readTxt('\\IMDB-valid.txt')\n",
    "        testDF = readTxt('\\IMDB-test.txt')\n",
    "    \n",
    "    majorityClassifier = DummyClassifier(strategy='most_frequent')\n",
    "    majorityClassifier.fit(createBagOfWordsMatrix(trainingDF, dictionary), trainingDF[1])\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = majorityClassifier.predict(createBagOfWordsMatrix(trainingDF, dictionary))\n",
    "    testScores(predictionsArray, trainingDF[1])\n",
    "    \n",
    "    print('Validation F1-Measure')\n",
    "    predictionsArray = majorityClassifier.predict(createBagOfWordsMatrix(validDF, dictionary))\n",
    "    testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = majorityClassifier.predict(createBagOfWordsMatrix(testDF, dictionary))\n",
    "    testScores(predictionsArray, testDF[1])\n",
    "    \n",
    "# baselineClassifier('IMDB')\n",
    "majorityClassifier('yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB\n",
      "Training F1-Measure\n",
      "F1 Score: 0.871295845531\n",
      "Confusion Matrix:\n",
      " [[6663  837]\n",
      " [1093 6407]]\n",
      "Validation F1-Measure\n",
      "F1 Score: 0.842861266874\n",
      "Confusion Matrix:\n",
      " [[4293  707]\n",
      " [ 864 4136]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.835917809086\n",
      "Confusion Matrix:\n",
      " [[10844  1656]\n",
      " [ 2442 10058]]\n"
     ]
    }
   ],
   "source": [
    "def bernoulliNB(dataset):\n",
    "    print(dataset)\n",
    "    if dataset == 'yelp':\n",
    "        dictionary = createDictionary('yelp')\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "        validDF = readTxt('\\yelp-valid.txt')\n",
    "        testDF = readTxt('\\yelp-test.txt')\n",
    "    elif dataset == 'IMDB':\n",
    "        dictionary = createDictionary('IMDB')\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "        validDF = readTxt('\\IMDB-valid.txt')\n",
    "        testDF = readTxt('\\IMDB-test.txt')\n",
    "        \n",
    "    clf = BernoulliNB()\n",
    "    clf.fit(createBagOfWordsMatrix(trainingDF, dictionary, 'Frequency'), trainingDF[1])\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(trainingDF, dictionary, 'Frequency'))\n",
    "    testScores(predictionsArray, trainingDF[1])\n",
    "    \n",
    "    print('Validation F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(validDF, dictionary, 'Frequency'))\n",
    "    testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(testDF, dictionary, 'Frequency'))\n",
    "    testScores(predictionsArray, testDF[1])\n",
    "    \n",
    "bernoulliNB('IMDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp\n",
      "Training F1-Measure\n",
      "F1 Score: 1.0\n",
      "Confusion Matrix:\n",
      " [[ 522    0    0    0    0]\n",
      " [   0  641    0    0    0]\n",
      " [   0    0  997    0    0]\n",
      " [   0    0    0 2468    0]\n",
      " [   0    0    0    0 2372]]\n",
      "Validation F1-Measure\n",
      "F1 Score: 0.279822135371\n",
      "Confusion Matrix:\n",
      " [[ 19  13  14  14  24]\n",
      " [ 13  11  17  24  31]\n",
      " [  8  21  40  58  37]\n",
      " [ 19  31  57 137 112]\n",
      " [ 15  17  31 110 127]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.276493554759\n",
      "Confusion Matrix:\n",
      " [[ 24  24  27  31  37]\n",
      " [ 22  28  42  57  41]\n",
      " [ 11  33  59 133  64]\n",
      " [ 37  44  91 278 252]\n",
      " [ 25  35  60 237 308]]\n"
     ]
    }
   ],
   "source": [
    "def decisionTree(dataset):\n",
    "    print(dataset)\n",
    "    if dataset == 'yelp':\n",
    "        dictionary = createDictionary('yelp')\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "        validDF = readTxt('\\yelp-valid.txt')\n",
    "        testDF = readTxt('\\yelp-test.txt')\n",
    "    elif dataset == 'IMDB':\n",
    "        dictionary = createDictionary('IMDB')\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "        validDF = readTxt('\\IMDB-valid.txt')\n",
    "        testDF = readTxt('\\IMDB-test.txt')\n",
    "        \n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    clf.fit(createBagOfWordsMatrix(trainingDF, dictionary), trainingDF[1])\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(trainingDF, dictionary))\n",
    "    testScores(predictionsArray, trainingDF[1])\n",
    "    \n",
    "    print('Validation F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(validDF, dictionary))\n",
    "    testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(testDF, dictionary))\n",
    "    testScores(predictionsArray, testDF[1])\n",
    "    \n",
    "decisionTree('yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp\n",
      "Training F1-Measure\n",
      "F1 Score: 0.997870801179\n",
      "Confusion Matrix:\n",
      " [[ 520    0    0    0    2]\n",
      " [   0  640    0    0    1]\n",
      " [   0    0  996    1    0]\n",
      " [   0    0    0 2454   14]\n",
      " [   0    0    0    2 2370]]\n",
      "Validation F1-Measure\n",
      "F1 Score: 0.413428426203\n",
      "Confusion Matrix:\n",
      " [[ 36  23   8   9   8]\n",
      " [ 14  25  15  28  14]\n",
      " [  7  23  50  65  19]\n",
      " [ 10  11  32 170 133]\n",
      " [  4   9  18 102 167]]\n",
      "Test F1-Measure\n",
      "F1 Score: 0.401651918294\n",
      "Confusion Matrix:\n",
      " [[ 56  33  15  19  20]\n",
      " [ 33  58  41  36  22]\n",
      " [ 12  42  77 118  51]\n",
      " [ 12  31  84 340 235]\n",
      " [ 15  12  40 237 361]]\n"
     ]
    }
   ],
   "source": [
    "def linearSVC(dataset):\n",
    "    print(dataset)\n",
    "    if dataset == 'yelp':\n",
    "        dictionary = createDictionary('yelp')\n",
    "        trainingDF = readTxt('\\yelp-train.txt')\n",
    "        validDF = readTxt('\\yelp-valid.txt')\n",
    "        testDF = readTxt('\\yelp-test.txt')\n",
    "    elif dataset == 'IMDB':\n",
    "        dictionary = createDictionary('IMDB')\n",
    "        trainingDF = readTxt('\\IMDB-train.txt')\n",
    "        validDF = readTxt('\\IMDB-valid.txt')\n",
    "        testDF = readTxt('\\IMDB-test.txt')\n",
    "        \n",
    "    clf = LinearSVC()\n",
    "    clf.fit(createBagOfWordsMatrix(trainingDF, dictionary), trainingDF[1])\n",
    "    \n",
    "    print('Training F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(trainingDF, dictionary))\n",
    "    testScores(predictionsArray, trainingDF[1])\n",
    "    \n",
    "    print('Validation F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(validDF, dictionary))\n",
    "    testScores(predictionsArray, validDF[1])\n",
    "    \n",
    "    print('Test F1-Measure')\n",
    "    predictionsArray = clf.predict(createBagOfWordsMatrix(testDF, dictionary))\n",
    "    testScores(predictionsArray, testDF[1])\n",
    "    \n",
    "linearSVC('yelp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
